experiment_name = "multichain_1000"

workspace_dir = output

tracker_cmd = 'run_tracker.sh'
# tracker_run_remote =
tracker_port = 7788

experiment_server_cmd = 'experiment_server.py'

# Command used to start (the local part of) the experiment. This will be executed concurrently with its remote counterpart if set (see below)
local_instance_cmd = "process_guard.py -c multichain_client.py -c multichain_client.py -c multichain_client.py -c multichain_client.py -c multichain_client.py -c multichain_client.py -c multichain_client.py -c multichain_client.py -c multichain_client.py -c multichain_client.py -c multichain_client.py -c multichain_client.py -c multichain_client.py -c multichain_client.py -c multichain_client.py -c multichain_client.py"
# Defaults to true
use_local_venv = False
experiment_time = 600
# Port where we should listen on. (required)
sync_port = __unique_port__
# Override the experiment synchronization server host to which the sync clients will try to connect to (default is HEAD_HOST)
sync_host = 127.0.0.1
# Number of sync clients we should wait for to be registered before starting the experiment. (default is DAS4_INSTANCES_TO_RUN)
sync_subscribers_amount = 16
sync_experiment_start_delay = 1
local_output_dir ="output"
output_dir = "output/multichain"

post_process_cmd = 'post_process_multichain.sh'
 
# Run R scripts to generate a graph
#r_scripts_to_run = "generate_multichain_graph.r"
